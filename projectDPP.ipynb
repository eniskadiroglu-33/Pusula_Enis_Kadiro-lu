{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a5df0f03-9345-4e71-849f-e6b7130fe12c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "129a90b8-5b3a-400f-a726-8a4fccd2521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuvenliEtiketleyici(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Scikit-Learn Pipeline ile uyumlu, güvenli bir LabelEncoder.\n",
    "    Her sütun için ayrı bir LabelEncoder uygular ve eğitim setinde\n",
    "    görülmeyen yeni kategorileri ('unknown') -1 olarak kodlar.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.kodlayicilar = {}\n",
    "        self.sutunlar = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Veri tipine göre sütun isimlerini belirle\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.sutunlar = X.columns\n",
    "            X_dizi = X.values\n",
    "        else:\n",
    "            X_dizi = X\n",
    "            self.sutunlar = [f\"sutun_{i}\" for i in range(X.shape[1])]\n",
    "        \n",
    "        # Her sütun için ayrı bir LabelEncoder eğit\n",
    "        for i, sutun_adi in enumerate(self.sutunlar):\n",
    "            kodlayici = LabelEncoder()\n",
    "            # NaN değerlerini geçici bir kategoriyle değiştirerek uyumlu hale getir\n",
    "            gecerli_veri = np.where(pd.isna(X_dizi[:, i]), 'EKSİK_DEGER', X_dizi[:, i].astype(str))\n",
    "            kodlayici.fit(gecerli_veri)\n",
    "            self.kodlayicilar[sutun_adi] = kodlayici\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_dizi = X.values if isinstance(X, pd.DataFrame) else X\n",
    "        sonuc = np.zeros_like(X_dizi, dtype=float)\n",
    "\n",
    "        # Her sütunu eğitilmiş kodlayıcı ile dönüştür\n",
    "        for i, sutun_adi in enumerate(self.sutunlar):\n",
    "            kodlayici = self.kodlayicilar[sutun_adi]\n",
    "            gecerli_veri = np.where(pd.isna(X_dizi[:, i]), 'EKSİK_DEGER', X_dizi[:, i].astype(str))\n",
    "            \n",
    "            # Bilinmeyen kategorileri -1, bilinenleri ise kendi kodlarıyla değiştir\n",
    "            donusturulmus_sutun = [\n",
    "                kodlayici.transform([deger])[0] if deger in kodlayici.classes_ else -1\n",
    "                for deger in gecerli_veri\n",
    "            ]\n",
    "            sonuc[:, i] = donusturulmus_sutun\n",
    "        return sonuc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "38958d95-1a49-4250-8883-7224e7c7eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VeriOnIsleyici:\n",
    "    \"\"\"\n",
    "    Veri ön işleme sürecini yöneten ana sınıf.\n",
    "    Veriyi yükler, temizler ve bir Scikit-Learn Pipeline'ı aracılığıyla işler.\n",
    "    \"\"\"\n",
    "    def __init__(self, dosya_yolu):\n",
    "        self.dosya_yolu = dosya_yolu\n",
    "        self.orijinal_veri = None\n",
    "        self.hazirlanmis_veri = None\n",
    "        self.tam_pipeline = None\n",
    "\n",
    "    def veri_yukle(self):\n",
    "        \"\"\"Excel dosyasını yükler ve sütun isimlerindeki boşlukları temizler.\"\"\"\n",
    "        try:\n",
    "            temiz_yol = self.dosya_yolu.replace(\"\\u202a\", \"\").replace(\"\\u202c\", \"\")\n",
    "            self.orijinal_veri = pd.read_excel(temiz_yol)\n",
    "            self.orijinal_veri.columns = self.orijinal_veri.columns.str.strip()\n",
    "            print(f\" Veri başarıyla yüklendi. Boyut: {self.orijinal_veri.shape}\")\n",
    "            return self.orijinal_veri\n",
    "        except FileNotFoundError:\n",
    "            print(f\" HATA: '{self.dosya_yolu}' dosyası bulunamadı.\")\n",
    "            sys.exit()\n",
    "\n",
    "    def kapsamli_temizlik(self):\n",
    "        \"\"\"Veri seti üzerinde tüm temizlik adımlarını uygular.\"\"\"\n",
    "        if self.orijinal_veri is None:\n",
    "            print(\" HATA: Önce veri yüklenmelidir. `veri_yukle()` metodunu çalıştırın.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n Veri temizliği başlıyor...\")\n",
    "        df = self.orijinal_veri.copy()\n",
    "\n",
    "        kaldirilacak_sutunlar = ['HastaNo', 'KanGrubu']\n",
    "        df.drop(columns=kaldirilacak_sutunlar, inplace=True, errors='ignore')\n",
    "\n",
    "        df.dropna(subset=['Bolum'], inplace=True)\n",
    "        \n",
    "        if 'UygulamaSuresi' in df.columns:\n",
    "            df['UygulamaSuresi_Dakika'] = df['UygulamaSuresi'].astype(str).str.extract(r'(\\d+)').astype(float)\n",
    "            medyan_deger = df['UygulamaSuresi_Dakika'].median()\n",
    "            df['UygulamaSuresi_Dakika'].fillna(medyan_deger, inplace=True)\n",
    "            df.drop('UygulamaSuresi', axis=1, inplace=True)\n",
    "\n",
    "        doldurulacak_degerler = {'Alerji': 'Yok', 'KronikHastalik': 'Yok', 'UygulamaYerleri': 'Bilinmiyor'}\n",
    "        for sutun, deger in doldurulacak_degerler.items():\n",
    "            if sutun in df.columns:\n",
    "                df[sutun].fillna(deger, inplace=True)\n",
    "\n",
    "        if 'Cinsiyet' in df.columns and df['Cinsiyet'].isnull().sum() > 0:\n",
    "            mod_deger = df['Cinsiyet'].mode()[0]\n",
    "            df['Cinsiyet'].fillna(mod_deger, inplace=True)\n",
    "\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        \n",
    "        self.hazirlanmis_veri = df\n",
    "        print(f\" Temizlik tamamlandı! Son boyut: {df.shape}\")\n",
    "        return self.hazirlanmis_veri\n",
    "\n",
    "    def pipeline_olustur_ve_calistir(self, hedef_sutun, test_orani=0.2, random_state=42):\n",
    "        \"\"\"Veri işleme pipeline'ını kurar, veriyi eğitir ve dönüştürür.\"\"\"\n",
    "        if self.hazirlanmis_veri is None:\n",
    "            print(\" HATA: Önce veri temizlenmelidir. `kapsamli_temizlik()` metodunu çalıştırın.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n Ön işleme pipeline'ı oluşturuluyor ve çalıştırılıyor...\")\n",
    "        \n",
    "        X = self.hazirlanmis_veri.drop(columns=[hedef_sutun])\n",
    "        y = self.hazirlanmis_veri[hedef_sutun]\n",
    "\n",
    "        sayisal_sutunlar = X.select_dtypes(include=np.number).columns.tolist()\n",
    "        kategorik_sutunlar = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "        print(f\" Sayısal Sütunlar ({len(sayisal_sutunlar)} adet): {sayisal_sutunlar}\")\n",
    "        print(f\" Kategorik Sütunlar ({len(kategorik_sutunlar)} adet): {kategorik_sutunlar}\")\n",
    "\n",
    "        sayisal_pipeline = Pipeline(steps=[\n",
    "            ('doldurucu', SimpleImputer(strategy='median')),\n",
    "            ('olcekleme', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        kategorik_pipeline = Pipeline(steps=[\n",
    "            ('doldurucu', SimpleImputer(strategy='constant', fill_value='EKSİK_DEGER')),\n",
    "            ('etiketleyici', GuvenliEtiketleyici())\n",
    "        ])\n",
    "\n",
    "        on_isleyici = ColumnTransformer(transformers=[\n",
    "            ('sayisal', sayisal_pipeline, sayisal_sutunlar),\n",
    "            ('kategorik', kategorik_pipeline, kategorik_sutunlar)\n",
    "        ])\n",
    "\n",
    "        self.tam_pipeline = Pipeline(steps=[('on_isleyici', on_isleyici)])\n",
    "\n",
    "        X_egitim, X_test, y_egitim, y_test = train_test_split(\n",
    "            X, y, test_size=test_orani, random_state=random_state, stratify=y\n",
    "        )\n",
    "        \n",
    "        X_egitim_islenmis = self.tam_pipeline.fit_transform(X_egitim)\n",
    "        X_test_islenmis = self.tam_pipeline.transform(X_test)\n",
    "        \n",
    "        print(\"Pipeline başarıyla çalıştırıldı.\")\n",
    "        \n",
    "        return X_egitim_islenmis, X_test_islenmis, y_egitim, y_test\n",
    "\n",
    "    def veri_ozeti_goster(self, df, baslik=\"Veri Özeti\"):\n",
    "        \"\"\"DataFrame hakkında basit bir özet bilgi yazdırır.\"\"\"\n",
    "        print(f\"\\n === {baslik.upper()} ===\")\n",
    "        print(f\"Boyut: {df.shape}\")\n",
    "        eksik_degerler = df.isnull().sum()\n",
    "        eksik_deger_sutunlari = eksik_degerler[eksik_degerler > 0]\n",
    "        if not eksik_deger_sutunlari.empty:\n",
    "            print(\"Eksik Değerler:\")\n",
    "            print(eksik_deger_sutunlari)\n",
    "        else:\n",
    "            print(\" Eksik değer bulunmuyor.\")\n",
    "        print(\"-\" * 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c9cbcba4-7dfa-46e4-8ce5-2be64d89da7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- PROJE AYARLARI ---\n",
    "DOSYA_YOLU = r\"C:\\Users\\Enis\\Downloads\\projectpus.xlsx\"\n",
    "HEDEF_DEGISKEN = 'TedaviSuresi'\n",
    "TEST_VERI_ORANI = 0.2\n",
    "RANDOM_STATE = 42\n",
    "# --------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4e1f589e-f5a1-421a-8b75-6b6acc85f8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " VERİ ÖN İŞLEME PİPELİNE'I BAŞLATILIYOR \n",
      " Veri başarıyla yüklendi. Boyut: (2235, 13)\n",
      "\n",
      " === İŞLEM ÖNCESI VERI ===\n",
      "Boyut: (2235, 13)\n",
      "Eksik Değerler:\n",
      "Cinsiyet           169\n",
      "KanGrubu           675\n",
      "KronikHastalik     611\n",
      "Bolum               11\n",
      "Alerji             944\n",
      "Tanilar             75\n",
      "UygulamaYerleri    221\n",
      "dtype: int64\n",
      "------------------------------\n",
      "\n",
      " Veri temizliği başlıyor...\n",
      " Temizlik tamamlandı! Son boyut: (1277, 11)\n",
      "\n",
      " === TEMIZLIK SONRASI VERI ===\n",
      "Boyut: (1277, 11)\n",
      "Eksik Değerler:\n",
      "Tanilar    46\n",
      "dtype: int64\n",
      "------------------------------\n",
      "\n",
      " Ön işleme pipeline'ı oluşturuluyor ve çalıştırılıyor...\n",
      " Sayısal Sütunlar (2 adet): ['Yas', 'UygulamaSuresi_Dakika']\n",
      " Kategorik Sütunlar (8 adet): ['Cinsiyet', 'Uyruk', 'KronikHastalik', 'Bolum', 'Alerji', 'Tanilar', 'TedaviAdi', 'UygulamaYerleri']\n",
      "Pipeline başarıyla çalıştırıldı.\n"
     ]
    }
   ],
   "source": [
    "print(\" VERİ ÖN İŞLEME PİPELİNE'I BAŞLATILIYOR \")\n",
    "\n",
    "# 1. Sınıfı başlat ve veriyi yükle\n",
    "isleyici = VeriOnIsleyici(DOSYA_YOLU)\n",
    "isleyici.veri_yukle()\n",
    "\n",
    "# 2. İşlem öncesi veri özetini göster\n",
    "isleyici.veri_ozeti_goster(isleyici.orijinal_veri, \"İşlem Öncesi Veri\")\n",
    "\n",
    "# 3. Veriyi temizle\n",
    "temiz_veri = isleyici.kapsamli_temizlik()\n",
    "\n",
    "# 4. Temizlik sonrası veri özetini göster (temiz_veri None değilse)\n",
    "if temiz_veri is not None:\n",
    "    isleyici.veri_ozeti_goster(temiz_veri, \"Temizlik Sonrası Veri\")\n",
    "\n",
    "    # 5. Pipeline'ı çalıştır ve sonuçları al\n",
    "    X_egitim_islenmis, X_test_islenmis, y_egitim, y_test = isleyici.pipeline_olustur_ve_calistir(\n",
    "        hedef_sutun=HEDEF_DEGISKEN,\n",
    "        test_orani=TEST_VERI_ORANI,\n",
    "        random_state=RANDOM_STATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "74c6ce80-d58a-4ff8-ae35-a617791ece1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " PİPELİNE TAMAMLANDI! \n",
      "========================================\n",
      " SONUÇ ÖZETİ:\n",
      " İşlenmiş Eğitim Verisi Boyutu: (1021, 10)\n",
      " İşlenmiş Test Verisi Boyutu:  (256, 10)\n",
      " Eğitim Hedef Değişkeni Sayısı: 1021\n",
      " Test Hedef Değişkeni Sayısı:  256\n",
      "\n",
      " Artık makine öğrenmesi modellerini eğitebilirsiniz.\n",
      "   Kullanım: `model.fit(X_egitim_islenmis, y_egitim)`\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n PİPELİNE TAMAMLANDI! \")\n",
    "print(\"=\" * 40)\n",
    "print(\" SONUÇ ÖZETİ:\")\n",
    "print(f\" İşlenmiş Eğitim Verisi Boyutu: {X_egitim_islenmis.shape}\")\n",
    "print(f\" İşlenmiş Test Verisi Boyutu:  {X_test_islenmis.shape}\")\n",
    "print(f\" Eğitim Hedef Değişkeni Sayısı: {len(y_egitim)}\")\n",
    "print(f\" Test Hedef Değişkeni Sayısı:  {len(y_test)}\")\n",
    "print(\"\\n Artık makine öğrenmesi modellerini eğitebilirsiniz.\")\n",
    "print(\"   Kullanım: `model.fit(X_egitim_islenmis, y_egitim)`\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba1691-7bef-435c-a376-c63a1c3deb7f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
